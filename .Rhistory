library(dnn)
install.packages("dnn")
library(dnn)
# Set seed for reproducibility
set.seed(1234)
# Number of patients
n <- 1000
# Function to generate random treatments based on given proportions
assign_treatments <- function(n, proportions) { treatments <- c("A", "B", "P") sample(treatments, size = n, replace = TRUE, prob = proportions) }
# Clear the environment
rm(list = ls())
# Load required libraries
library(data.table)
library(survival)
library(MASS)
library(missForest)
library(mice)
library(sn)
library(ggplot2)
library(purrr)
library(emplik)
library(rms)
library(caret)
library(rootSolve)
library(scorecard)
library(dplyr)
library(bujar)
library(patchwork)
library(dnn)
# Set seed for reproducibility
set.seed(1234)
# Number of patients
n <- 1000
# Function to generate random treatments based on given proportions
assign_treatments <- function(n, proportions) {
treatments <- c("A", "B", "P")
sample(treatments, size = n, replace = TRUE, prob = proportions)
}
# Stage 1: Initial treatment assignment and patient data generation
states_stage1 <- data.table(
Treatment = assign_treatments(n, c(1/3, 1/3, 1/3)),
TumorSize = numeric(n),
Severity = numeric(n),
survival.month.1st = numeric(n)
)
# Define Tumor Size and Severity based on treatment in Stage 1
states_stage1$TumorSize[states_stage1$Treatment == "A"] <- runif(sum(states_stage1$Treatment == "A"), 5, 6)
states_stage1$TumorSize[states_stage1$Treatment == "B"] <- runif(sum(states_stage1$Treatment == "B"), 3, 4)
states_stage1$TumorSize[states_stage1$Treatment == "P"] <- runif(sum(states_stage1$Treatment == "P"), 1, 2)
states_stage1$Severity <- as.numeric(factor(states_stage1$Treatment, levels = c("A", "B", "P"), labels = c(3, 2, 1)))
# Generate survival time for Stage 1 using a non-linear model
states_stage1$survival.month.1st <- 20 - states_stage1$TumorSize^0.9 - log(states_stage1$Severity + 1) + rnorm(n, 0, 2)
combined_data <- data.table(
Treatment1 = states_stage1$Treatment,
Survival1 = states_stage1$survival.month.1st,
Treatment_Combination = paste0(states_stage1$Treatment),
Total_Survival = states_stage1$survival.month.1st
)
combined_data
# Censoring
Censoring <- runif(n, 10, 20)
delta <- ifelse(states_stage1$survival.month.1st <= Censoring, 1, 0)
mean(delta)
states_stage1$y <- pmin(states_stage1$survival.month.1st, Censoring)
states_stage1$delta <- delta
# Buckley-James AFT model function
bjaft <- function(dt, tol = 1e-3, max.iter = 100) {
Y <- dt$y
delta <- dt$delta
x <- cbind(dt$TumorSize, dt$Severity)
old.beta <- lm(log(Y) ~ x)$coef[-1]
err <- 10
iter <- 0
while (max.iter > iter & err > tol) {
xbeta <- c(x %*% old.beta)
e <- log(Y) - xbeta
es <- sort(e)
sfit <- survfit(Surv(e, delta) ~ 1)
Fhat <- 1 - approx(x = sfit$time, y = sfit$surv, xout = es)$y
dF <- diff(c(0, Fhat))
denom <- 1 - Fhat
num <- rev(cumsum(rev(es * dF)))
Yimp <- (num / pmax(tol, denom))[rank(e)] + xbeta
Yhat <- log(Y) * delta + (1 - delta) * Yimp
new.beta <- lm(Yhat ~ x)$coef[-1]
err <- max(abs(new.beta - old.beta))
iter <- iter + 1
old.beta <- new.beta
}
list(coef = round(new.beta, 3), iter = iter, Yhat = Yhat)
}
# Buckley-James AFT model imputation
imputed_Yhat <- exp(bjaft(states_stage1)$Yhat)
combined_data$Survival.sum <- imputed_Yhat
Imputed.data <- data.frame(combined_data$Treatment_Combination, as.numeric(combined_data$Survival.sum))
# Plotting
p1 <- ggplot(combined_data, aes(x = Treatment_Combination, y = Total_Survival)) +
geom_boxplot() +
labs(title = "True Survival", x = "Treatment Combination", y = "Survival Time")
p2 <- ggplot(Imputed.data, aes(x = factor(Imputed.data[, 1]), y = Imputed.data[, 2])) +
geom_boxplot() +
labs(title = "BJ", x = "Treatment Combination", y = "Survival Time")
################################################################################
# BJ twin boosting with componentwise least squares + Q learning ###############
################################################################################
imputed.y <- bujar(y = log(states_stage1$y), cens = states_stage1$delta, x = cbind(states_stage1$TumorSize, states_stage1$Severity),
cv = FALSE, mstop = 1000, twin = TRUE, mstop2 = 100)$ynew
BJLS <- exp(imputed.y)
p4 <- ggplot(Imputed.data, aes(x = factor(Imputed.data[, 1]), y = BJLS)) +
geom_boxplot() +
labs(title = "BJ-Imputation (Twin Boosting)", x = "Treatment Combination", y = "Survival Time")
################################################################################
# BJ boosting with regression stumps (BJ-Tree) + Q learning ####################
################################################################################
BJTree <- exp(bujar(y = log(states_stage1$y), cens = states_stage1$delta,
x = states_stage1[, c("TumorSize", "Severity")],
learner = "tree", tuning = TRUE, cv = FALSE, degree = 4,
mstop = 1000, n.cores = 1, rng = 123)$ynew)
p5 <- ggplot(Imputed.data, aes(x = factor(Imputed.data[, 1]), y = BJTree)) +
geom_boxplot() +
labs(title = "BJ-Imputation (Tree)", x = "Treatment Combination", y = "Survival Time")
p3 <- ggplot(Imputed.data, aes(x = factor(Imputed.data[, 1]), y = states_stage1$y)) +
geom_boxplot() +
labs(title = "Non-Imputed Survival", x = "Treatment Combination", y = "Survival Time")
# Deep Learning
x <- data.frame(TumorSize = states_stage1$TumorSize, Severity = states_stage1$Severity)
x <- as.matrix(x)
input_shape <- ncol(x)
model <- dNNmodel(units = c(4, 4, 1), activation = c("relu", "softmax", "sigmoid"), input_shape = input_shape)
time <- states_stage1$y
status <- states_stage1$delta
fit <- deepAFT(Surv(time, status) ~ TumorSize + Severity, data = states_stage1, model = model, method = "BuckleyJames")
fit
imputed_times <- exp(fit$predictor)
imputed_times
tuned_params <- hyperTuning(x, Surv(time, status), model, method = "BuckleyJames")
best_model <- tuned_params$model
best_model
fit.best <- deepAFT(Surv(time, status) ~ TumorSize + Severity, data = states_stage1, model = best_model, method = "BuckleyJames")
fit.best
imputed_times_best <- exp(fit.best$predictor)
imputed_times_best
BJ.Deep.Imputed <- data.frame(
Treatment_Combination = states_stage1$Treatment,
Status = states_stage1$delta,
Imputed_Time = imputed_times_best
)
p6 <- ggplot(BJ.Deep.Imputed, aes(x = Treatment_Combination, y = Imputed_Time)) +
geom_boxplot() +
labs(title = "BJ-Imputation (Deep Learning)", x = "Treatment Combination", y = "Survival Time")
# Combine all plots
y_limits <- c(10,25)
p1 <- p1 + ylim(y_limits)
p3 <- p3 + ylim(y_limits)
p4 <- p4 + ylim(y_limits)
p5 <- p5 + ylim(y_limits)
p6 <- p6 + ylim(y_limits)
combined_plot <- p1 + p4 + p5 + p6 + p3 + plot_layout(ncol = 5)
print(combined_plot)
install.packages("asaur")
library(asaur)
data("ashkenazi")
635/5
sum(flip)
library(ggplot2)
library(dplyr)
# Create a data frame
data <- data.frame(
Date = as.Date(c(
"2024-01-01", "2023-02-01", "2023-03-01", "2023-05-01", "2023-06-01",
"2023-07-01", "2023-09-01", "2023-11-01", "2023-12-01", "2022-01-01",
"2022-03-01", "2022-05-01", "2022-06-01", "2022-07-01", "2022-09-01",
"2022-11-01", "2022-12-01", "2021-01-01", "2021-03-01", "2021-04-01",
"2021-06-01", "2021-07-01", "2021-09-01", "2021-11-01", "2021-12-01",
"2020-01-01", "2020-03-03", "2020-03-15", "2020-03-23", "2020-04-01",
"2020-06-01", "2020-07-01", "2020-09-01", "2020-11-01", "2020-12-01",
"2019-01-01", "2019-03-01", "2019-05-01", "2019-06-01", "2019-07-01",
"2019-09-01", "2019-10-11", "2019-10-30", "2019-12-01")),
Positive = c(
60, 54.5, 54.5, 54.5, 70, 54.5, 60, 60, 45.5, 50, 45.5, 41.7, 54.5,
66.7, 63.6, 41.7, 41.7, 69.2, 41.7, 33.3, 38.5, 30.8, 38.5, 46.7, 53.8,
38.5, 60, 56.2, 50, 54.5, 58.3, 75, 53.8, 41.7, 41.7, 70, 54.5, 63.6,
54.5, 41.7, 58.3, 70, 46.2, 50),
Negative = c(
40, 45.5, 45.5, 45.5, 30, 45.5, 40, 40, 54.5, 50, 54.5, 58.3, 45.5,
33.3, 36.4, 58.3, 58.3, 30.8, 58.3, 66.7, 61.5, 69.2, 61.5, 53.3, 46.2,
61.5, 40, 43.8, 50, 45.5, 41.7, 25, 46.2, 58.3, 58.3, 30, 45.5, 36.4,
45.5, 58.3, 41.7, 30, 53.8, 50)
)
# Calculate the total of positive and negative sentiments
total_positive <- sum(data$Positive)
total_negative <- sum(data$Negative)
# Create a data frame containing the totals
summary_data <- data.frame(
Sentiment = c("Positive", "Negative"),
Total = c(total_positive, total_negative)
)
# Add percentage labels
summary_data$Percent <- summary_data$Total / sum(summary_data$Total) * 100
# Create a pie chart
pie_chart <- ggplot(summary_data, aes(x = "", y = Total, fill = Sentiment)) +
geom_bar(stat = "identity", width = 1) +
coord_polar("y", start = 0) +
labs(title = "Total Sentiment of FOMC Files") +
scale_fill_manual(values = c("Green", "Orange")) +
theme_void()
# Add percentage labels to the pie chart
pie_chart + geom_text(aes(label = paste(round(Percent, 1), "%")), position = position_stack(vjust = 0.5))
library(ggplot2)
library(dplyr)
# Create a data frame
data <- data.frame(
Date = as.Date(c(
"2024-01-01", "2023-02-01", "2023-03-01", "2023-05-01", "2023-06-01",
"2023-07-01", "2023-09-01", "2023-11-01", "2023-12-01", "2022-01-01",
"2022-03-01", "2022-05-01", "2022-06-01", "2022-07-01", "2022-09-01",
"2022-11-01", "2022-12-01", "2021-01-01", "2021-03-01", "2021-04-01",
"2021-06-01", "2021-07-01", "2021-09-01", "2021-11-01", "2021-12-01",
"2020-01-01", "2020-03-03", "2020-03-15", "2020-03-23", "2020-04-01",
"2020-06-01", "2020-07-01", "2020-09-01", "2020-11-01", "2020-12-01",
"2019-01-01", "2019-03-01", "2019-05-01", "2019-06-01", "2019-07-01",
"2019-09-01", "2019-10-11", "2019-10-30", "2019-12-01")),
Positive = c(
60, 54.5, 54.5, 54.5, 70, 54.5, 60, 60, 45.5, 50, 45.5, 41.7, 54.5,
66.7, 63.6, 41.7, 41.7, 69.2, 41.7, 33.3, 38.5, 30.8, 38.5, 46.7, 53.8,
38.5, 60, 56.2, 50, 54.5, 58.3, 75, 53.8, 41.7, 41.7, 70, 54.5, 63.6,
54.5, 41.7, 58.3, 70, 46.2, 50),
Negative = c(
40, 45.5, 45.5, 45.5, 30, 45.5, 40, 40, 54.5, 50, 54.5, 58.3, 45.5,
33.3, 36.4, 58.3, 58.3, 30.8, 58.3, 66.7, 61.5, 69.2, 61.5, 53.3, 46.2,
61.5, 40, 43.8, 50, 45.5, 41.7, 25, 46.2, 58.3, 58.3, 30, 45.5, 36.4,
45.5, 58.3, 41.7, 30, 53.8, 50)
)
# Calculate the total of positive and negative sentiments
total_positive <- sum(data$Positive)
total_negative <- sum(data$Negative)
# Create a data frame containing the totals
summary_data <- data.frame(
Sentiment = c("Positive", "Negative"),
Total = c(total_positive, total_negative)
)
# Add percentage labels
summary_data$Percent <- summary_data$Total / sum(summary_data$Total) * 100
summary_data$Percent
summary_data
library(ggplot2)
library(dplyr)
data <- data.frame(
Date = as.Date(c(
"2024-01-01", "2023-02-01", "2023-03-01", "2023-05-01", "2023-06-01",
"2023-07-01", "2023-09-01", "2023-11-01", "2023-12-01", "2022-01-01",
"2022-03-01", "2022-05-01", "2022-06-01", "2022-07-01", "2022-09-01",
"2022-11-01", "2022-12-01", "2021-01-01", "2021-03-01", "2021-04-01",
"2021-06-01", "2021-07-01", "2021-09-01", "2021-11-01", "2021-12-01",
"2020-01-01", "2020-03-03", "2020-03-15", "2020-03-23", "2020-04-01",
"2020-06-01", "2020-07-01", "2020-09-01", "2020-11-01", "2020-12-01",
"2019-01-01", "2019-03-01", "2019-05-01", "2019-06-01", "2019-07-01",
"2019-09-01", "2019-10-11", "2019-10-30", "2019-12-01")),
Positive = c(
60, 54.5, 54.5, 54.5, 70, 54.5, 60, 60, 45.5, 50, 45.5, 41.7, 54.5,
66.7, 63.6, 41.7, 41.7, 69.2, 41.7, 33.3, 38.5, 30.8, 38.5, 46.7, 53.8,
38.5, 60, 56.2, 50, 54.5, 58.3, 75, 53.8, 41.7, 41.7, 70, 54.5, 63.6,
54.5, 41.7, 58.3, 70, 46.2, 50),
Negative = c(
40, 45.5, 45.5, 45.5, 30, 45.5, 40, 40, 54.5, 50, 54.5, 58.3, 45.5,
33.3, 36.4, 58.3, 58.3, 30.8, 58.3, 66.7, 61.5, 69.2, 61.5, 53.3, 46.2,
61.5, 40, 43.8, 50, 45.5, 41.7, 25, 46.2, 58.3, 58.3, 30, 45.5, 36.4,
45.5, 58.3, 41.7, 30, 53.8, 50)
)
ggplot(data, aes(x = Date)) +
geom_line(aes(y = Positive, color = "Positive"), size = 1.2) +
geom_line(aes(y = Negative, color = "Negative"), size = 1.2) +
labs(x = "Date", y = "Percentage", title = "Statement Sentiment Over Time") +
scale_color_manual(name = "Sentiment", values = c(Positive = "blue", Negative = "red")) +
theme_minimal()
library(sde)
library(fda)
library(fdapace)
library(PBO)
library(far)
L = 1001					#	L is the number of measurements per day
N = 200					#	N is the number of days of data
### Simulation 1
set.seed(1)
#	The matrix 'error' has 'N' rows--each representing a single day.
#	Each row has L elements--each representing a measurement at a different
#	time of the day.  Note that var(error(t))=1 for all t.
#start here ########################################################
error = matrix(,N,L)
t=seq(from = 0, to = 1, length.out = L)
for (day in 1:N)
{
#error[day,] = BM(x=0, t0=0, T=1, (L-1))
error[day,] = BBridge(x=0, y=0, t0=0, T=1, (L-1)) + sqrt(1-t*(1-t))*rnorm(1)
}
rm(day,t)
data1<-error
### Simulation 1
set.seed(2)
#	The matrix 'error' has 'N' rows--each representing a single day.
#	Each row has L elements--each representing a measurement at a different
#	time of the day.  Note that var(error(t))=1 for all t.
#start here ########################################################
error = matrix(,N,L)
t=seq(from = 0, to = 1, length.out = L)
for (day in 1:N)
{
#error[day,] = BM(x=0, t0=0, T=1, (L-1))
error[day,] = BBridge(x=0, y=0, t0=0, T=1, (L-1)) + sqrt(1-t*(1-t))*rnorm(1)
}
rm(day,t)
data2<-error
### Simulation 3
set.seed(3)
#	The matrix 'error' has 'N' rows--each representing a single day.
#	Each row has L elements--each representing a measurement at a different
#	time of the day.  Note that var(error(t))=1 for all t.
#start here ########################################################
error = matrix(,N,L)
t=seq(from = 0, to = 1, length.out = L)
for (day in 1:N)
{
#error[day,] = BM(x=0, t0=0, T=1, (L-1))
error[day,] = BBridge(x=0, y=0, t0=0, T=1, (L-1)) + sqrt(1-t*(1-t))*rnorm(1)
}
rm(day,t)
data3<-error
### Simulation 4
set.seed(4)
#	The matrix 'error' has 'N' rows--each representing a single day.
#	Each row has L elements--each representing a measurement at a different
#	time of the day.  Note that var(error(t))=1 for all t.
#start here ########################################################
error = matrix(,N,L)
t=seq(from = 0, to = 1, length.out = L)
for (day in 1:N)
{
#error[day,] = BM(x=0, t0=0, T=1, (L-1))
error[day,] = BBridge(x=0, y=0, t0=0, T=1, (L-1)) + sqrt(1-t*(1-t))*rnorm(1)
}
rm(day,t)
data4<-error
plot(error[N,])
dim(data4)
library("funData")
y1<-t(data1[,c(1:1000)])
y2<-t(data2[,c(1:1000)])
y3<-t(data3[,c(1:1000)])
y4<-t(data4[,c(1:1000)])
dim(y1)
f1<-funData(argvals=seq(0,1,length.out=200),X=matrix(y1, nrow = 1000))
f1
class(f1)
f2<-funData(argvals=seq(0,1,length.out=200),X=matrix(y2, nrow = 1000))
f2
class(f2)
f3<-funData(argvals=seq(0,1,length.out=200),X=matrix(y3, nrow = 1000))
f3
class(f3)
f4<-funData(argvals=seq(0,1,length.out=200),X=matrix(y4, nrow = 1000))
f4
class(f4)
#coercetomultiFunDataobject(oflength1)
m1<-multiFunData(f1,f2,f3,f4)
m1
par(mfrow = c(1,4))
plot(m1[[1]], main = "Y1(t,s)")
plot(m1[[2]], main = "Y2(t,s)")
plot(m1[[3]], main = "Y3(t,s)")
plot(m1[[4]], main = "Y4(t,s)")
par(mfrow = c(1,1))
library(MFPCA)
# MFPCA based on univariate spline expansions
splines <- MFPCA(m1, M = 4, uniExpansions = list(list(type = "splines1D", k = 50),
list(type = "splines1D", k = 50),
list(type = "splines1D", k = 50),
list(type = "splines1D", k = 50)),
fit = TRUE) # calculate reconstruction, too
summary(splines)
eigen <-splines$vectors
y11<-y1
y21<-y2
y31<-y3
y41<-y4
y12<-t(data1[,c(2:1001)])
RMSE1.vineigen<-RMSE1.eigen<-RMSE1.vine<-NULL
RMSE1.vineigen<-RMSE1.eigen<-RMSE1.vine<-matrix(rep(0,1000),1000,1)
RMSE1.vineigenQ1<-RMSE1.eigenQ1<-RMSE1.vineQ1<-NULL
RMSE1.vineigenQ1<-RMSE1.eigenQ1<-RMSE1.vineQ1<-matrix(rep(0,1000),1000,1)
RMSE1.vineigenQ2<-RMSE1.eigenQ2<-RMSE1.vineQ2<-NULL
RMSE1.vineigenQ2<-RMSE1.eigenQ2<-RMSE1.vineQ2<-matrix(rep(0,1000),1000,1)
RMSE1.vineigenQ3<-RMSE1.eigenQ3<-RMSE1.vineQ3<-NULL
RMSE1.vineigenQ3<-RMSE1.eigenQ3<-RMSE1.vineQ3<-matrix(rep(0,1000),1000,1)
RMSE.vineigen<-RMSE.eigen<-RMSE.vine<-NULL
RMSE.vineigen<-RMSE.eigen<-RMSE.vine<-matrix(rep(0,1000),1000,1)
RMSE.vineigenQ1<-RMSE.eigenQ1<-RMSE.vineQ1<-NULL
RMSE.vineigenQ1<-RMSE.eigenQ1<-RMSE.vineQ1<-matrix(rep(0,1000),1000,1)
RMSE.vineigenQ2<-RMSE.eigenQ2<-RMSE.vineQ2<-NULL
RMSE.vineigenQ2<-RMSE.eigenQ2<-RMSE.vineQ2<-matrix(rep(0,1000),1000,1)
RMSE.vineigenQ3<-RMSE.eigenQ3<-RMSE.vineQ3<-NULL
RMSE.vineigenQ3<-RMSE.eigenQ3<-RMSE.vineQ3<-matrix(rep(0,1000),1000,1)
# ARL
#library(spc)
#library(CUSUMdesign)
z<-1000
vineigen.Y_LCL<-eigen.Y_LCL<-vine.Y_LCL<-0
vineigen.YQ1_LCL<-eigen.YQ1_LCL<-vine.YQ1_LCL<-0
vineigen.YQ2_LCL<-eigen.YQ2_LCL<-vine.YQ2_LCL<-0
vineigen.YQ3_LCL<-eigen.YQ3_LCL<-vine.YQ3_LCL<-0
vineigen.Y_UCL<-eigen.Y_UCL<-vine.Y_UCL<-0
vineigen.YQ1_UCL<-eigen.YQ1_UCL<-vine.YQ1_UCL<-0
vineigen.YQ2_UCL<-eigen.YQ2_UCL<-vine.YQ2_UCL<-0
vineigen.YQ3_UCL<-eigen.YQ3_UCL<-vine.YQ3_UCL<-0
vineigen.Y_CL<-eigen.Y_CL<-vine.Y_CL<-0
vineigen.YQ1_CL<-eigen.YQ1_CL<-vine.YQ1_CL<-0
vineigen.YQ2_CL<-eigen.YQ2_CL<-vine.YQ2_CL<-0
vineigen.YQ3_CL<-eigen.YQ3_CL<-vine.YQ3_CL<-0
vineigen.Y_coverage<-eigen.Y_coverage<-vine.Y_coverage<-0
vineigen.YQ1_coverage<-eigen.YQ1_coverage<-vine.YQ1_coverage<-0
vineigen.YQ2_coverage<-eigen.YQ2_coverage<-vine.YQ2_coverage<-0
vineigen.YQ3_coverage<-eigen.YQ3_coverage<-vine.YQ3_coverage<-0
vineigen.Y_RL0<-eigen.Y_RL0<-vine.Y_RL0<-NULL
vineigen.YQ1_RL0<-eigen.YQ1_RL0<-vine.YQ1_RL0<-NULL
vineigen.YQ2_RL0<-eigen.YQ2_RL0<-vine.YQ2_RL0<-NULL
vineigen.YQ3_RL0<-eigen.YQ3_RL0<-vine.YQ3_RL0<-NULL
vineigen.Y_RL0<-eigen.Y_RL0<-vine.Y_RL0<-rep(0,z)
vineigen.YQ1_RL0<-eigen.YQ1_RL0<-vine.YQ1_RL0<-rep(0,z)
vineigen.YQ2_RL0<-eigen.YQ2_RL0<-vine.YQ2_RL0<-rep(0,z)
vineigen.YQ3_RL0<-eigen.YQ3_RL0<-vine.YQ3_RL0<-rep(0,z)
vineigen.Y_ARL.0a<-eigen.Y_ARL.0a<-vine.Y_ARL.0a<-NULL
vineigen.YQ1_ARL.0a<-eigen.YQ1_ARL.0a<-vine.YQ1_ARL.0a<-NULL
vineigen.YQ2_ARL.0a<-eigen.YQ2_ARL.0a<-vine.YQ2_ARL.0a<-NULL
vineigen.YQ3_ARL.0a<-eigen.YQ3_ARL.0a<-vine.YQ3_ARL.0a<-NULL
vineigen.Y_ARL.0a<-eigen.Y_ARL.0a<-vine.Y_ARL.0a<-rep(0,z)
vineigen.YQ1_ARL.0a<-eigen.YQ1_ARL.0a<-vine.YQ1_ARL.0a<-rep(0,z)
vineigen.YQ2_ARL.0a<-eigen.YQ2_ARL.0a<-vine.YQ2_ARL.0a<-rep(0,z)
vineigen.YQ3_ARL.0a<-eigen.YQ3_ARL.0a<-vine.YQ3_ARL.0a<-rep(0,z)
q<-2
gene<-cbind(eigen, y11[q,],y21[q,],y31[q,],y41[q,], y12[q,])
#-----------------------------------------------------------------------------#
#   Transform data to standard uniform d.f. through its empirical d.f.        #
#-----------------------------------------------------------------------------#
Empiric.df<-function(data,x)
{	data<-sort(data)
if(min(data)>0) a<-0 else a<-floor(min(data)/100)*100
if(max(data)<0) b<-0 else b<-ceiling(max(data)/100)*100
for(j in 1:length(x))
{
if(x[j]<a) x[j]<-a
if(x[j]>b) x[j]<-b
}
data<-c(a,data,b)
n<-length(data)
p<-c(rep(0,(n-1)))
q<-c(rep(0,(n-1)))
for(i in 2:(n-2))
{
p[i]<-(data[i]+data[i+1])/2
q[i]<-(i-1)/(n-2)
}
p[1]<-a
p[n-1]<-b
q[1]<-0
q[n-1]<-1
approx(p,q,xout=c(x))$y
}
#--------------------------- Initial values ---------------------------------#
col1.n <- length(gene[1,]); col1.n
row1.n <- length(gene[,1]); n <- row1.n; n
#=============================================================================#
#                 Step to transform original data to U(0,1)                   #
#=============================================================================#
Emp1.index <- matrix(rep(0,n*col1.n),n,col1.n)
for(i in 1:col1.n){
Emp1.index[,i] <- Empiric.df(gene[,i],gene[,i])
}
Emp.index <- data.frame(Emp1.index)
Emp<-Emp.index
data1 <- data.frame(Emp)
colnames(data1)<-c("X1", "X2", "X3", "X4", "X5", "X6", "X7", "X8","Y")
#colnames(data1)<-c("X1", "X2", "X3", "X4","Y")
library(vinereg)
y1.vineigen<-vinereg( Y-mean(Y)~
X1+X2+X3+X4+X5+X6+X7+X8, data=data1)
y1.eigen<-vinereg( Y-mean(Y)~
X1+X2+X3+X4, data=data1)
y1.vine<-vinereg( Ymean(Y)~
X5+X6+X7+X8, data=data1)
y1.vine<-vinereg( Y-mean(Y)~
X5+X6+X7+X8, data=data1)
pvineigen <-predict(y1.vineigen, newdata = data1, alpha=NA) #mean
pvineigenm1<-(pvineigen$mean)
resvineigen.y1<- (data1$Y) - pvineigenm1
pvineigenm<-(pvineigen$mean)^2
resvineigen.y<- (data1$Y-mean(data1$Y))^2 - pvineigenm
pvineigenm1<-(pvineigen$mean)
resvineigen.y1<- (data1$Y-mean(data1$Y)) - pvineigenm1
pvineigenm<-(pvineigen$mean)^2
resvineigen.y<- (data1$Y-mean(data1$Y))^2 - pvineigenm
peigen <-predict(y1.eigen, newdata = data1, alpha=NA) #mean
peigenm1<-(peigen$mean)
setwd("C:/Users/kjono/Dropbox/Documents/My Paper/JAS/spatiotempDQN")
library(devtools)
# Create a new package folder
create("spatiotempDQN")
devtools::install()
devtools::install()
library(spatiotempDQN)
devtools::document()
devtools::install()
devtools::document()
devtools::install()
